{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:37:45.833412Z",
     "start_time": "2024-07-25T05:37:45.275672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# required models and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ],
   "id": "9e9a763f1d56a6e2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:37:51.567052Z",
     "start_time": "2024-07-25T05:37:45.835814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the dataset\n",
    "adult_df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", names=[\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \n",
    "\"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"], skipinitialspace=True)\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = adult_df.drop('income', axis=1)\n",
    "y = adult_df['income']\n",
    "\n",
    "# Encode categorical variables\n",
    "encoder = OrdinalEncoder()\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Calculate feature importances\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_encoded, y)\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Calculate cumulative importances\n",
    "cumulative_importances = np.cumsum(importances)\n",
    "\n",
    "# Find number of features for cumulative importance of 95%\n",
    "num_features = np.where(cumulative_importances > 0.95)[0][0] + 1\n",
    "\n",
    "# Extract the names of the most important features\n",
    "feature_names = list(X.columns)\n",
    "important_feature_names = [feature_names[i] for i in np.argsort(importances)[-num_features:]]\n",
    "\n",
    "# Extract the most important features\n",
    "important_features = X_encoded[:, np.argsort(importances)[-num_features:]]"
   ],
   "id": "281fa122ec7fa43",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:38:44.814095Z",
     "start_time": "2024-07-25T05:37:51.568937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract the most important features\n",
    "important_features = X_encoded[:, np.argsort(importances)[-num_features:]]\n",
    "\n",
    "# Handle the skewed nature of the data by over sampeling on class to match the training points for both the classes, This will help the model pick up the patterns better for both the models.\n",
    "positive_class = np.where(y == '>50K')[0]\n",
    "negative_class = np.where(y == '<=50K')[0]\n",
    "\n",
    "# Oversample the minority class\n",
    "negative_class = np.random.choice(negative_class, size=len(positive_class), replace=True)\n",
    "\n",
    "# Combine the positive and negative classes\n",
    "X_train = np.concatenate([important_features[positive_class], important_features[negative_class]], axis=0)\n",
    "y_train = np.concatenate([y[positive_class], y[negative_class]], axis=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model using the most important features\n",
    "rf = RandomForestClassifier(n_estimators=5000, random_state=84)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Calculate the classification report\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Print the accuracy score and the classification report\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)"
   ],
   "id": "35bad1bd90def6a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8460312400382531\n",
      "Classification Report:\n",
      " {'<=50K': {'precision': 0.8506700701978303, 'recall': 0.8426042983565107, 'f1-score': 0.8466179739599873, 'support': 1582.0}, '>50K': {'precision': 0.8414012738853504, 'recall': 0.8495176848874598, 'f1-score': 0.84544, 'support': 1555.0}, 'accuracy': 0.8460312400382531, 'macro avg': {'precision': 0.8460356720415902, 'recall': 0.8460609916219852, 'f1-score': 0.8460289869799936, 'support': 3137.0}, 'weighted avg': {'precision': 0.8460755600716249, 'recall': 0.8460312400382531, 'f1-score': 0.8460340563610775, 'support': 3137.0}}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:38:48.806785Z",
     "start_time": "2024-07-25T05:38:44.815816Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# testing the performance of the new model on unknown dataset\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Load the new dataset\n",
    "test_df = pd.read_csv(\"adult.test\", names=[\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
    "\"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"income\"], skipinitialspace=True)\n",
    "test_df.drop(\"race\", axis=1, inplace=True)\n",
    "\n",
    "# Split the new dataset into features and target\n",
    "X_new = test_df.drop('income', axis=1)\n",
    "y_new = test_df['income']\n",
    "y_new = y_new.str.replace('.', '')\n",
    "\n",
    "encoder_new = OrdinalEncoder()\n",
    "input_data_encoded = encoder_new.fit_transform(X_new)\n",
    "# Make a prediction using the trained model\n",
    "prediction = rf.predict(input_data_encoded)\n",
    "\n",
    "print(accuracy_score(y_new, prediction))\n",
    "print(classification_report(y_new, prediction, output_dict=True))"
   ],
   "id": "f28e35992bdcd0aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7639579878385848\n",
      "{'<=50K': {'precision': 0.764141662567634, 'recall': 0.999437072778448, 'f1-score': 0.8660928952228301, 'support': 12435.0}, '>50K': {'precision': 0.5882352941176471, 'recall': 0.0026001040041601664, 'f1-score': 0.0051773233238415735, 'support': 3846.0}, 'accuracy': 0.7639579878385848, 'macro avg': {'precision': 0.6761884783426406, 'recall': 0.5010185883913041, 'f1-score': 0.4356351092733358, 'support': 16281.0}, 'weighted avg': {'precision': 0.7225879562192126, 'recall': 0.7639579878385848, 'f1-score': 0.6627220156992437, 'support': 16281.0}}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T05:38:48.812621Z",
     "start_time": "2024-07-25T05:38:48.808022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Given the fianl testing results I am looking at a reduced performance of ~-8%.\n",
    "\n",
    "The model is overfitted in some capacity as clearly it has a low precision of ~59% when it come to detecting the \">50K\" class and that degradation is high when it come to detecting the <=50K.\n",
    "\n",
    "To fix this I applied increased over sampling of the \">50K\" class to match it against the \"<=50K\" class, and while this did result in improved performance it was less than anticipated. I am still looking better ways to train models on skewed datasets.\n",
    "\n",
    "For both the classes I was trying to find rules in this dataset but came up empty handed. \n",
    "\"\"\""
   ],
   "id": "f2561a84ac3f3f47",
   "outputs": [],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
